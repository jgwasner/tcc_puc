{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orquestrador de Chatbots - Etapa 2\n",
    "-----------------------------------\n",
    "## Limpeza, Vocabulário e Vetorização\n",
    "\n",
    "1. Limpeza dos Dados\n",
    "2. Construção do Vocabulário\n",
    "3. Geração do vetorizador\n",
    "4. Pesistência dos dados processados, do vocabulário e do vetorizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import codecs\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import orquestrador_funcoes_gerais as ofg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conferir as configurações antes de prosseguir\n",
      "nome_arquivo_configuracao: config.json\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "aplicar_stemmer: False\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "bots: [{'bot_id': 1, 'nome': 'Alistamento Militar', 'arquivo': 'skill-alistamento-militar.json'}, {'bot_id': 2, 'nome': 'COVID', 'arquivo': 'skill-covid.json'}, {'bot_id': 3, 'nome': 'Login Único', 'arquivo': 'skill-login-unico.json'}, {'bot_id': 4, 'nome': 'IRPF 2020', 'arquivo': 'skill-perguntao-irpf-2020.json'}, {'bot_id': 5, 'nome': 'PGMEI', 'arquivo': 'skill-pgmei.json'}, {'bot_id': 6, 'nome': 'Selo Turismo Responsável', 'arquivo': 'skill-poc-selo-turismo-responsavel.json'}, {'bot_id': 7, 'nome': 'Cadastur', 'arquivo': 'skill-cadastur.json'}, {'bot_id': 8, 'nome': 'Tuberculose', 'arquivo': 'skill-tuberculose.json'}]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "diretorio_skills: skills\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "diretorio_dados: dados\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "diretorio_modelos: modelos\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "arquivo_perguntas_zero: bots_perguntas_0.csv\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "arquivo_todas: bots_perguntas_todas.csv\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "arquivo_treino_testes: treino_testes.csv\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "arquivo_validacao: validacao.csv\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "arquivo_validacao_com_zero: validacao_com_0.csv\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "arquivo_treino_testes_processado: treino_testes_processado.csv\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "arquivo_vocabulario: vocabulario.txt\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "arquivo_vetorizador: vetorizador.pkl\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "padrao_arquivo_classificador_base: clf_base_%classe%.pkl\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "padrao_arquivo_classificador_voting: clf_voting_%bot_id%.pkl\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "arquivo_classificador_voting: clf_voting.pkl\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "arquivo_informacoes: info.json\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "arquivo_resultados:\n",
      "  True: voting_resultados_com_stemmer.pkl\n",
      "  False: voting_resultados_sem_stemmer.pkl\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "validacao_size: 0.35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "random_state: 112020\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "vocab:\n",
      "  freq_min: 0\n",
      "  remover_frequentes: 0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "vetorizador:\n",
      "  ngram_range: [1, 2]\n",
      "  sublinear_tf: True\n",
      "  smooth_idf: False\n",
      "  norm: l2\n",
      "  vector_vocab: False\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cfg = ofg.carregar_configuracoes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bots=cfg['bots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATENÇÃO!!! Aplicação de Stemmer = False\n"
     ]
    }
   ],
   "source": [
    "print('ATENÇÃO!!! Aplicação de Stemmer =', cfg['aplicar_stemmer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar e preparar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros carregados: 2650 de treino_testes.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bot_id</th>\n",
       "      <th>pergunta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tenho MAIS DE 18 devo me alistar?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>aperto de mao transmite tuberculose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>A DIÁRIA TERÁ UM VALOR MAIOR para quem aderir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>preciso de uma conta de acesso no login unico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Como resolver problema de CPF inválido ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>4</td>\n",
       "      <td>filho como dependente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>4</td>\n",
       "      <td>o contribuinte esta obrigado ao preenchimento ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>5</td>\n",
       "      <td>Preciso imprimir a guia MEI em atraso. Como faço?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>7</td>\n",
       "      <td>o quer dizer CNAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>6</td>\n",
       "      <td>saiu novas orientaçoes de higiene como vou atu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2650 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bot_id                                           pergunta\n",
       "0          1                  tenho MAIS DE 18 devo me alistar?\n",
       "1          8                aperto de mao transmite tuberculose\n",
       "2          6  A DIÁRIA TERÁ UM VALOR MAIOR para quem aderir ...\n",
       "3          3      preciso de uma conta de acesso no login unico\n",
       "4          3           Como resolver problema de CPF inválido ?\n",
       "...      ...                                                ...\n",
       "2645       4                              filho como dependente\n",
       "2646       4  o contribuinte esta obrigado ao preenchimento ...\n",
       "2647       5  Preciso imprimir a guia MEI em atraso. Como faço?\n",
       "2648       7                                  o quer dizer CNAE\n",
       "2649       6  saiu novas orientaçoes de higiene como vou atu...\n",
       "\n",
       "[2650 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carrega o arquivo CSV com as perguntas de treino e teste\n",
    "arquivo_treino_testes = os.path.join(os.getcwd(),  cfg['diretorio_dados'], cfg['arquivo_treino_testes']) \n",
    "df = pd.read_csv(arquivo_treino_testes, index_col=None, engine='python', sep =',', encoding=\"utf-8\")\n",
    "print('Total de registros carregados:',len(df), 'de', cfg['arquivo_treino_testes'])\n",
    "\n",
    "# Exibe uma amostra dos dados carregados\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    1202\n",
       "6     389\n",
       "3     292\n",
       "1     237\n",
       "7     191\n",
       "8     151\n",
       "2     116\n",
       "5      72\n",
       "Name: bot_id, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribuição das classes nos dados fornecidos. Note que não há nenhum pergunta rotulada como \"0\" no arquivo de treino e testes\n",
    "# Há um grande desbalanceamento das classes. Futuramente vale considerar métodos mais sofisticados de balanceamento.\n",
    "df.bot_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bot_id</th>\n",
       "      <th>pergunta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dezoito devo alistar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>aperto mao transmite tuberculose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>diaria tera valor maior aderir selo turismo re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>preciso conta acesso login unico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>resolver problema cpf invalido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>4</td>\n",
       "      <td>filho dependente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>4</td>\n",
       "      <td>contribuinte obrigado preenchimento numero recibo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>5</td>\n",
       "      <td>preciso imprimir guia microempreendedor indivi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>7</td>\n",
       "      <td>quer dizer cnae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>6</td>\n",
       "      <td>saiu novas orientacoes higiene vou atualizar selo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2650 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bot_id                                           pergunta\n",
       "0          1                               dezoito devo alistar\n",
       "1          8                   aperto mao transmite tuberculose\n",
       "2          6  diaria tera valor maior aderir selo turismo re...\n",
       "3          3                   preciso conta acesso login unico\n",
       "4          3                     resolver problema cpf invalido\n",
       "...      ...                                                ...\n",
       "2645       4                                   filho dependente\n",
       "2646       4  contribuinte obrigado preenchimento numero recibo\n",
       "2647       5  preciso imprimir guia microempreendedor indivi...\n",
       "2648       7                                    quer dizer cnae\n",
       "2649       6  saiu novas orientacoes higiene vou atualizar selo\n",
       "\n",
       "[2650 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processa as perguntas, fazendo a limpeza dos textos\n",
    "df['pergunta'] = df['pergunta'].apply(lambda x: ofg.limpar_texto(x, cfg['aplicar_stemmer']))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerar Vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INÍCIO CONSTRUÇÃO VOCABULÁRIO.\n",
      "\n",
      "FIM CONSTRUÇÃO VOCABULÁRIO.\n",
      "\n",
      "Tamanho Vocabulário: 2135\n"
     ]
    }
   ],
   "source": [
    "df[\"tokens\"] = df[\"pergunta\"].apply(ofg.tokenizer.tokenize)\n",
    "freq_doc = dict()\n",
    "vocab = dict()\n",
    "\n",
    "print(\"\\nINÍCIO CONSTRUÇÃO VOCABULÁRIO.\")\n",
    "for index in range(len(df)):\n",
    "    tokens = df.at[index,'tokens']\n",
    "    for token in tokens:\n",
    "        if token in vocab:\n",
    "            vocab[token] += 1\n",
    "        else:\n",
    "            vocab[token] = 1\n",
    "    for token in set(tokens):\n",
    "        if token in freq_doc:\n",
    "            freq_doc[token] += 1\n",
    "        else:\n",
    "            freq_doc[token] = 1\n",
    "print(\"\\nFIM CONSTRUÇÃO VOCABULÁRIO.\\n\")\n",
    "\n",
    "vocabulario = list(vocab.keys())\n",
    "vocabulario.sort()\n",
    "print('Tamanho Vocabulário:',len(vocabulario))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo termos infrequentes.\n",
    "if cfg['vocab']['freq_min'] > 1:\n",
    "    print('Removendo termos infrequentes...')\n",
    "    vocab_df = pd.DataFrame({'palavra': list(vocab.keys()), 'frequencia': list(vocab.values())})\n",
    "    vocab_remover = list(vocab_df[vocab_df['frequencia'] < cfg['vocab']['freq_min']]['palavra'])\n",
    "    vocabulario = [p for p in vocabulario if p not in vocab_remover]\n",
    "    print(\"Tamanho do vocabulário após remoção de palavras infrequentes: \" + str(len(vocabulario)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remoção das N palavras mais presentes em documentos.\n",
    "if cfg['vocab']['remover_frequentes'] > 0:\n",
    "    freq_doc_df = pd.DataFrame({'palavra': list(freq_doc.keys()), 'freq_docs': list(freq_doc.values())})\n",
    "    palavras_freq_doc = freq_doc_df.sort_values(by=\"freq_docs\", ascending=False)[0:cfg['vocab']['remover_frequentes']]    \n",
    "\n",
    "    vocab_remover = list(palavras_freq_doc['palavra'])\n",
    "    vocabulario = [p for p in vocabulario if p not in vocab_remover]\n",
    "    print(\"Tamanho do vocabulário após remoção de palavras muito frequentes: \" + str(len(vocabulario)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Adequando texto ao vocabulário\n",
    "    for index in range(len(df)):\n",
    "        tokens = ofg.tokenizer.tokenize(df.at[index,'pergunta'])\n",
    "        tokens = [palavra for palavra in tokens if palavra in vocabulario]\n",
    "        df.at[index,'pergunta'] = ' '.join(tokens)\n",
    "    print('Textos foram adaptados ao vocabulário')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvar Vocabulário e Textos Processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de salvar, elimina perguntas abaixo de um certo tamanho\n",
    "mask = (df['pergunta'].str.len() > 4)\n",
    "df = df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textos processados salvos em E:\\DataScience\\PUC\\TCC\\tcc_orquestrador_bots_final\\dados\\treino_testes_processado.csv\n"
     ]
    }
   ],
   "source": [
    "# Salva textos processados\n",
    "arquivo_treino_testes_processado = os.path.join(os.getcwd(),  cfg['diretorio_dados'], cfg['arquivo_treino_testes_processado'])\n",
    "df.to_csv(arquivo_treino_testes_processado, index=False, columns=['bot_id', 'pergunta'])\n",
    "print('Textos processados salvos em',arquivo_treino_testes_processado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulário salvo em E:\\DataScience\\PUC\\TCC\\tcc_orquestrador_bots_final\\dados\\vocabulario.txt\n"
     ]
    }
   ],
   "source": [
    "# Salva vocabulário\n",
    "arquivo_vocab = os.path.join(os.getcwd(), cfg['diretorio_dados'], cfg['arquivo_vocabulario'])\n",
    "\n",
    "txt = ''\n",
    "for palavra in vocabulario:\n",
    "    txt += palavra + '\\n'\n",
    "f = open(arquivo_vocab, 'w')\n",
    "f.write(txt)\n",
    "f.close()\n",
    "print('Vocabulário salvo em', arquivo_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar e Salvar Vetorizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(ngram_range=[1, 2], smooth_idf=False, sublinear_tf=True)\n"
     ]
    }
   ],
   "source": [
    "cfg_vect = cfg['vetorizador']\n",
    "\n",
    "if cfg_vect['vector_vocab']:\n",
    "    vectorizer = TfidfVectorizer(ngram_range=cfg_vect['ngram_range'], vocabulary=vocabulario)\n",
    "else:\n",
    "    vectorizer = TfidfVectorizer(ngram_range=cfg_vect['ngram_range'], sublinear_tf=cfg_vect['sublinear_tf'], \n",
    "                                 smooth_idf=cfg_vect['smooth_idf'], vocabulary=None, norm=cfg_vect['norm'])\n",
    "    \n",
    "vectorizer.fit_transform(df['pergunta'].tolist())\n",
    "print(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vetorizador persistido em E:\\DataScience\\PUC\\TCC\\tcc_orquestrador_bots_final\\modelos\\vetorizador.pkl\n"
     ]
    }
   ],
   "source": [
    "# Persistindo o vetorizador\n",
    "arquivo_vetorizador = os.path.join(os.getcwd(), cfg['diretorio_modelos'], cfg['arquivo_vetorizador'])\n",
    "\n",
    "with open(arquivo_vetorizador, \"wb\") as vectorizer_file:\n",
    "    pickle.dump(vectorizer, vectorizer_file)\n",
    "print('Vetorizador persistido em', arquivo_vetorizador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fim da etapa 2!\n"
     ]
    }
   ],
   "source": [
    "print('Fim da etapa 2!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
